# Вопросы по архитектуре - Allegro Orders Backup

## Критические вопросы, требующие уточнения

### 1. Механизм идентификации пользователей
**Вопрос**: Какой формат user_id предпочтителен - UUID, строка, или целое число?
**Контекст**: Необходимо определить тип данных для user_id, который будет использоваться как внешний ключ идентификации.
**Варианты**:
**Ответ**: UUID

### 2. Device Code Flow интеграция
**Вопрос**: Как должен проходить процесс регистрации нового токена через Device Code Flow?
**Контекст**: Нужно определить API flow для пользователя от инициации до сохранения токена.
**Подвопросы**:
- Должен ли микросервис самостоятельно инициировать Device Code Flow?
**Ответ**: Да микросервис должен инициировать Device Code Flow естественно по запросу.
    Нужен роут который инициализирует создание токена, от пользователя потребуется ввести Название аккаунта, дальше пользователь должен получить авторизационную ссылку по которой ему нужно перейти, а в селери в это время должен запуститься процесс ожидания и проверки подтверждения, например на несколько минут, и как только пользователь авторизуется, токен должен быть сохранен в базу.


### 3. Rate Limiting стратегия
**Вопрос**: Какие ограничения накладывает Allegro API на количество запросов?
**Контекст**: Необходимо спроектировать механизм соблюдения rate limits.
**Подвопросы**:
- Какие лимиты по количеству запросов в минуту/час?
- Есть ли отдельные лимиты для разных типов API (авторизация, заказы)?
- Как обрабатывать 429 ошибки?
**Ответ**: 
- **Базовые лимиты**: 1000 запросов в минуту для большинства endpoints
- **Orders API**: Специальные лимиты для order/checkout-forms - 100 запросов в минуту
- **Events API**: order/events имеет лимит 60 запросов в минуту
- **Авторизация**: Device code flow - 10 запросов в минуту
- **Обработка 429**: Использовать exponential backoff, заголовок Retry-After
- **Мониторинг**: Следить за заголовками X-RateLimit-Remaining, X-RateLimit-Reset
- **Стратегия**: Реализовать очереди задач с контролем скорости в Celery

### 4. Структура данных заказов
**Вопрос**: В каком формате Allegro возвращает данные заказов?
**Контекст**: Нужно определить, как сохранять заказы в JSONB поле.
**Ответ**:
**Основные поля заказа**:
- `id` - UUID заказа
- `status` - статус заказа (BOUGHT, FILLED_IN, READY_FOR_PROCESSING, etc.)
- `buyer` - информация о покупателе (login, email, preferences)
- `payment` - данные о платеже (amount, currency, status, type)
- `delivery` - информация о доставке (address, method, cost, time)
- `lineItems` - товары в заказе (название, количество, цена, SKU)
- `createdAt`, `updatedAt` - временные метки
- `marketplace` - информация о площадке (allegro-pl, allegro-cz, etc.)

**События заказов** (GET /order/events):
- `id` - UUID события
- `order.id` - ID заказа  
- `type` - тип события (ORDER_STATUS_CHANGED, PAYMENT_STATUS_CHANGED, etc.)
- `occurredAt` - время события
- `order` - данные заказа на момент события

**Рекомендации**:
- Сохранять полный JSON ответ в JSONB для гибкости
- Создать дополнительные индексы на ключевые поля (status, buyer.login, createdAt)
- Версионирование схемы данных для обработки изменений API

### 5. Интервалы автоматической синхронизации
**Вопрос**: Как часто должна происходить автоматическая синхронизация?
**Контекст**: Баланс между актуальностью данных и нагрузкой на API.
**Варианты**:
- Каждые 15 минут - максимальная актуальность
- Каждый час - средний вариант
- Каждые 6 часов - минимальная нагрузка
**Факторы**:
- Частота появления новых заказов у пользователей
- Rate limits Allegro API
- Нагрузка на систему
**Ответ**: Начать с 6 часов, сделать настраиваемым

---

## Технические детали, требующие проработки

### 6. Обработка токенов истечения
**Вопрос**: Что делать с токенами, которые не удается обновить?
**Сценарий**: Refresh token истек или пользователь отозвал доступ.
**Варианты**:
- Деактивировать токен и прекратить синхронизацию
- Уведомлять пользователя о необходимости повторной авторизации
- Логировать и продолжать попытки обновления
**Ответ**: Деактивировать + логирование

### 7. Конфликты данных и синхронизация изменений
**Вопрос**: Как обрабатывать ситуации, когда заказ изменился в Allegro?
**Решение через Events API**:
**Стратегия**: Использовать GET /order/events для event-driven синхронизации
**Алгоритм**:
1. **Отслеживание событий**: Регулярно опрашивать /order/events с параметром from=lastSyncTimestamp
2. **Типы событий**:
   - ORDER_STATUS_CHANGED - изменение статуса заказа
   - PAYMENT_STATUS_CHANGED - изменение статуса платежа  
   - DELIVERY_INFO_CHANGED - изменение данных доставки
   - ORDER_CANCELLED - отмена заказа
3. **Обработка событий**:
   - Получить событие с order.id и occurredAt
   - Загрузить полные данные заказа через GET /order/checkout-forms/{id}
   - Обновить запись в БД, сохранив timestamp события
4. **Избежание дублирования**: Проверять timestamp последнего обновления перед записью
5. **История изменений**: Логировать все события в отдельную таблицу order_events

**Преимущества**:
- Минимальная нагрузка на API (только новые события)
- Актуальные данные в режиме реального времени
- Избежание конфликтов при одновременном доступе

### 8. Объем данных заказов
**Вопрос**: Какой ожидается объем данных заказов на пользователя?
**Контекст**: Планирование производительности и storage.
**Подвопросы**:
- Средний размер одного заказа в JSON?
- Среднее количество заказов на пользователя в месяц?
- Нужна ли архивация старых заказов?
**Действие**: Получить примерные цифры от заказчика
**Ответ**: Размер данных должен иметь возможность большого расширения для сохранения ооочень давних заказов

### 9. Мониторинг и алерты
**Вопрос**: Какие критические события требуют немедленного уведомления?
**Варианты**:
- Критические ошибки синхронизации
- Недоступность Allegro API
- Превышение rate limits
- Ошибки базы данных
**Ответ**: Алерты на все критические ошибки

### 10. Backup и восстановление
**Вопрос**: Нужен ли механизм backup данных микросервиса?
**Контекст**: Данные заказов могут быть критически важными.
**Подвопросы**:
- Регулярные backup базы данных?
- Export данных в внешние системы?
- Механизм восстановления после сбоев?
**Рекомендация**: PostgreSQL backup + экспорт в S3
**Ответ**: PostgreSQL backup + экспорт в S3
---

## Архитектурные решения для обсуждения

### 11. Кэширование данных
**Вопрос**: Нужно ли кэшировать данные заказов для быстрого доступа?
**Контекст**: Оптимизация производительности API запросов.
**Варианты**:
- Redis кэш для часто запрашиваемых заказов
- In-memory кэш для метаданных пользователей
- Без кэширования - прямые запросы к БД
**Ответ**: Начать без кэша, добавить при необходимости

### 12. API версионирование
**Вопрос**: Как обрабатывать изменения в API микросервиса?
**Контекст**: Совместимость с клиентскими приложениями.
**Варианты**:
- URL versioning (/api/v1/, /api/v2/)
- Header versioning (Accept: application/vnd.api+json;version=1)
- Query parameter versioning (?version=1)
**Ответ**: URL versioning для простоты

### 13. Масштабирование
**Вопрос**: Как система должна масштабироваться при росте нагрузки?
**Аспекты**:
- Горизонтальное масштабирование API (load balancer)
- Масштабирование Celery workers
- Шардинг базы данных (при больших объемах)
- Кэширование на уровне CDN
**Ответ**: Подготовить архитектуру к горизонтальному масштабированию

---

## Интеграционные вопросы

### 14. Интеграция с внешними системами
**Вопрос**: Как микросервис будет интегрироваться с существующими системами?
**Контекст**: Определение протоколов взаимодействия.
**Подвопросы**:
- REST API для получения данных?
- Webhook уведомления о новых заказах?
- Message queue для асинхронного взаимодействия?
**Рекомендация**: REST API + опциональные webhooks
**Ответ**: Не совсем понимаю что есть message queue но в рекомендациях скорее всего верный ответ.

### 15. Аутентификация API микросервиса
**Вопрос**: Как защитить API эндпоинты микросервиса?
**Варианты**:
- API ключи для простоты
- JWT токены для более сложной авторизации
- mTLS для максимальной безопасности
- Без аутентификации (internal network)
**Ответ**: API ключи для начала

### 16. Логирование и мониторинг
**Вопрос**: Какой уровень детализации логов необходим?
**Аспекты**:
- Все API запросы и ответы?
- Только ошибки и важные события?
- Персональные данные в логах?
- Структурированные логи vs plain text?
**Рекомендация**: Структурированные логи, исключая персональные данные, Все апи запросы и ответы. 

---

## Дополнительные технические детали (на основе документации Allegro API)

### 17. Детали реализации синхронизации заказов
**Ключевые API endpoints**:

**GET /order/events**:
- Параметры: `from` (RFC3339 timestamp), `limit` (max 1000), `type[]` (фильтр событий)
- Возвращает: массив событий с полной информацией о заказе на момент события
- Rate limit: 60 запросов/минуту
- Рекомендация: запрашивать каждые 2-3 минуты

**GET /order/checkout-forms**:
- Параметры: `offset`, `limit` (max 1000), `status`, `createdAt.gte/lte`
- Для полной синхронизации: использовать пагинацию с createdAt фильтрами
- Rate limit: 100 запросов/минуту

**GET /order/checkout-forms/{id}**:
- Получение детальной информации о заказе
- Использовать только при необходимости дополнительных данных
- Rate limit: 1000 запросов/минуту

### 18. Обработка ошибок и граничных случаев
**HTTP коды ответов**:
- 401 Unauthorized - токен недействителен, требуется refresh
- 403 Forbidden - недостаточно прав доступа
- 429 Too Many Requests - превышен rate limit, используй Retry-After header
- 503 Service Unavailable - временная недоступность сервиса

**Стратегии retry**:
- Exponential backoff для 429 и 5xx ошибок
- Немедленный retry для network timeouts
- Максимум 3 попытки для критических операций

### 19. Структура базы данных (дополнения)
**Добавить таблицу order_events**:
```sql
CREATE TABLE order_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    order_id VARCHAR(255) NOT NULL,
    token_id UUID NOT NULL REFERENCES user_tokens(id),
    event_type VARCHAR(100) NOT NULL,
    occurred_at TIMESTAMP NOT NULL,
    event_data JSONB NOT NULL,
    processed_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(order_id, occurred_at, event_type)
);
```

**Индексы для производительности**:
```sql
CREATE INDEX idx_orders_token_created ON orders(token_id, created_at);
CREATE INDEX idx_orders_status ON orders USING gin((order_data->>'status'));
CREATE INDEX idx_order_events_occurred ON order_events(occurred_at);
CREATE INDEX idx_sync_history_token_timestamp ON sync_history(token_id, sync_timestamp);
```

---

## Приоритизация вопросов

### Критические (требуют решения до начала разработки):
1. Механизм идентификации пользователей
2. Device Code Flow интеграция
3. Rate Limiting стратегия

### Высокий приоритет (решить в процессе разработки этапа 1-2):
4. Структура данных заказов
5. Интервалы автоматической синхронизации
6. Обработка токенов истечения

### Средний приоритет (решить к этапу 3-4):
7. Конфликты данных
8. Объем данных заказов
9. Мониторинг и алерты

### Низкий приоритет (можно отложить):
10. Backup и восстановление
11. Кэширование данных
12. API версионирование
13. Масштабирование
14. Интеграция с внешними системами
15. Аутентификация API микросервиса
16. Логирование и мониторинг

---

**Создан**: 2024-01-15  
**Обновлен**: 2024-01-15  
**Статус**: Завершен - все критические вопросы получили ответы  
**Следующий review**: Перед началом этапа разработки 2 